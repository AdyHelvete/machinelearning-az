install.packages(tydiverse)
install.packages(tidyverse)
install.packages("tidyverse")
library(tidyverse)
data("iris")
colnames("iris")
colnames(iris)
dim(iris)
summary(iris)
iris$Setosa<-ifelse(iris$Species=="setosa",1,0)
iris$veriscolor<-(iris$Species=="veriscolor",1,0)
iris$veriscolor<-ifelse(iris$Species=="veriscolor",1,0)
iris$Species<-NULL
colnames(iris)
model<-lm(iris$Sepal.Length ~ iris$Sepal.Width+iris$Petal.Length+iris$Petal.Width+iris$Setosa+iris$veriscolor)
summary(iris)
summary(model)
iris$versicolor<-(iris$Species=="veriscolor",1,0)
iris$versicolor<-(iris$Species=="versicolor",1,0)
#Natural Lengual Processing
setwd("~/GitHub/machinelearning-az/ML-Practicas/P7 - Natural Lenguaje Procesing")
# importar el dataset
dataset=read.delim("Restaurant_Reviews.tsv",quote = '',stringsAsFactors = FALSE)
View(dataset)
#Limpieza de datos
install.packages("tm")
library(tm)
corpus=VCorpus(VectorSource(dataset$Review))
View(corpus)
corpus=tm_map(corpus,content_transformer(tolower))
#Consultar el primer elemento del corpus
as.character(corpus[[1]])
corpus=tm_map(corpus,removeNumbers)
corpus=tm_map(corpus,removePunctuation)
?stopwords
corpus=tm_map(corpus,removeWords,stopwords(kind = "en"))
#Limpieza de datos
#install.packages("tm")
install.packages("snowballC")
#Limpieza de datos
#install.packages("tm")
install.packages("SnowballC")
library(SnowballC)
corpus=tm_map(corpus,removeWords,stopwords(kind = "en"))
corpus=tm_map(corpus,stemDocument)
corpus=tm_map(corpus,stripWhitespace)
corpus=tm_map(corpus,stripWhitespace)
corpus=tm_map(corpus,stripWhitespace)
corpus=tm_map(corpus,stripWhitespace)
#Creación de matriz dispersa (Bag of Words)
dtm=DocumentTermMatrix(corpus)
View(dtm)
dtm=removeSparseTerms(dtm,0.99)
dtm
#Natural Lengual Processing
# importar el dataset
dataset=read.delim("Restaurant_Reviews.tsv",quote = '',stringsAsFactors = FALSE)
#Limpieza de datos
#install.packages("tm")
#install.packages("SnowballC")
library(tm)
library(SnowballC)
corpus=VCorpus(VectorSource(dataset$Review))
corpus=tm_map(corpus,content_transformer(tolower))
#Consultar el primer elemento del corpus
#as.character(corpus[[1]])
#Limpieza de los textos
corpus=tm_map(corpus,removeNumbers)
corpus=tm_map(corpus,removePunctuation)
corpus=tm_map(corpus,removeWords,stopwords(kind = "en"))
corpus=tm_map(corpus,stemDocument)
corpus=tm_map(corpus,stripWhitespace)
#Creación de matriz dispersa (Bag of Words)
dtm=DocumentTermMatrix(corpus)
dtm
dtm=removeSparseTerms(dtm,0.999)
dtm
dataset=as.data.frame(as.asmatrix(dtm))
dataset=as.data.frame(as.matrix(dtm))
View(dataset)
dataset_original=read.delim("Restaurant_Reviews.tsv",quote = '',stringsAsFactors = FALSE)
dataset$Liked=dataset_original$Liked
# En algunos casos (BAyes,random forest, descicion tree) Codificar la variable de clasificación como factor
dataset$Liked=factor(dataset$Liked,
levels=c(0,1))
#dividir los datos en conjuntos de entrenamiento y test
#install.packages("caTools")
library(caTools)
set.seed(123) #Semilla para aleatorios
split=sample.split(dataset$Purchased,SplitRatio =0.80)
training_set=subset(dataset,split==TRUE)
testing_set=subset(dataset,split==FALSE)
#Ajustar el clasificador Random Forest con el conjunto de entrenamiento
#Aqui
#install.packages("randomForest")
library(randomForest)
classifier=randomForest(x=training_set[,-692],
y=training_set$Liked,
ntree = 10)
#predicción de los resultados con el conjunto de testing
y_pred=predict(classifier,newdata = testing_set[,-692],
type="class")
#Crear matriz de confusión
cm=table(testing_set[,692],y_pred)
#Natural Lengual Processing
# importar el dataset
dataset_original=read.delim("Restaurant_Reviews.tsv",quote = '',stringsAsFactors = FALSE)
#Limpieza de datos
#install.packages("tm")
#install.packages("SnowballC")
library(tm)
library(SnowballC)
corpus=VCorpus(VectorSource(dataset$Review))
corpus=tm_map(corpus,content_transformer(tolower))
#Consultar el primer elemento del corpus
#as.character(corpus[[1]])
#Limpieza de los textos
corpus=tm_map(corpus,removeNumbers)
corpus=tm_map(corpus,removePunctuation)
corpus=tm_map(corpus,removeWords,stopwords(kind = "en"))
corpus=tm_map(corpus,stemDocument)
corpus=tm_map(corpus,stripWhitespace)
#Creación de matriz dispersa (Bag of Words)
dtm=DocumentTermMatrix(corpus)
dtm=removeSparseTerms(dtm,0.999)
dataset=as.data.frame(as.matrix(dtm))
dataset$Liked=dataset_original$Liked
# En algunos casos (BAyes,random forest, descicion tree) Codificar la variable de clasificación como factor
dataset$Liked=factor(dataset$Liked,
levels=c(0,1))
#dividir los datos en conjuntos de entrenamiento y test
#install.packages("caTools")
library(caTools)
set.seed(123) #Semilla para aleatorios
split=sample.split(dataset$Purchased,SplitRatio =0.80)
training_set=subset(dataset,split==TRUE)
testing_set=subset(dataset,split==FALSE)
#Ajustar el clasificador Random Forest con el conjunto de entrenamiento
#Aqui
#install.packages("randomForest")
library(randomForest)
classifier=randomForest(x=training_set[,-692],
y=training_set$Liked,
ntree = 10)
#predicción de los resultados con el conjunto de testing
y_pred=predict(classifier,newdata = testing_set[,-692],
type="class")
#Crear matriz de confusión
cm=table(testing_set[,692],y_pred)
#Natural Lengual Processing
# importar el dataset
dataset_original=read.delim("Restaurant_Reviews.tsv",quote = '',stringsAsFactors = FALSE)
#Limpieza de datos
#install.packages("tm")
#install.packages("SnowballC")
library(tm)
library(SnowballC)
corpus=VCorpus(VectorSource(dataset_original$Review))
corpus=tm_map(corpus,content_transformer(tolower))
#Consultar el primer elemento del corpus
#as.character(corpus[[1]])
#Limpieza de los textos
corpus=tm_map(corpus,removeNumbers)
corpus=tm_map(corpus,removePunctuation)
corpus=tm_map(corpus,removeWords,stopwords(kind = "en"))
corpus=tm_map(corpus,stemDocument)
corpus=tm_map(corpus,stripWhitespace)
#Creación de matriz dispersa (Bag of Words)
dtm=DocumentTermMatrix(corpus)
dtm=removeSparseTerms(dtm,0.999)
dataset=as.data.frame(as.matrix(dtm))
dataset$Liked=dataset_original$Liked
# En algunos casos (BAyes,random forest, descicion tree) Codificar la variable de clasificación como factor
dataset$Liked=factor(dataset$Liked,
levels=c(0,1))
#dividir los datos en conjuntos de entrenamiento y test
#install.packages("caTools")
library(caTools)
set.seed(123) #Semilla para aleatorios
split=sample.split(dataset$Purchased,SplitRatio =0.80)
training_set=subset(dataset,split==TRUE)
testing_set=subset(dataset,split==FALSE)
#Ajustar el clasificador Random Forest con el conjunto de entrenamiento
#Aqui
#install.packages("randomForest")
library(randomForest)
classifier=randomForest(x=training_set[,-692],
y=training_set$Liked,
ntree = 10)
#predicción de los resultados con el conjunto de testing
y_pred=predict(classifier,newdata = testing_set[,-692],
type="class")
#Crear matriz de confusión
cm=table(testing_set[,692],y_pred)
dataset=as.data.frame(as.matrix(dtm))
dataset$Liked=dataset_original$Liked
dataset$Liked=factor(dataset$Liked,
levels=c(0,1))
library(caTools)
set.seed(123) #Semilla para aleatorios
split=sample.split(dataset$Purchased,SplitRatio =0.80)
split=sample.split(dataset$Liked,SplitRatio =0.80)
training_set=subset(dataset,split==TRUE)
testing_set=subset(dataset,split==FALSE)
library(randomForest)
classifier=randomForest(x=training_set[,-692],
y=training_set$Liked,
ntree = 10)
#predicción de los resultados con el conjunto de testing
y_pred=predict(classifier,newdata = testing_set[,-692],
type="class")
#Crear matriz de confusión
cm=table(testing_set[,692],y_pred)
cm
classifier=randomForest(x=training_set[,-692],
y=training_set$Liked,
ntree = 20)
#predicción de los resultados con el conjunto de testing
y_pred=predict(classifier,newdata = testing_set[,-692],
type="class")
#Crear matriz de confusión
cm=table(testing_set[,692],y_pred)
cm
classifier=randomForest(x=training_set[,-692],
y=training_set$Liked,
ntree = 100)
#predicción de los resultados con el conjunto de testing
y_pred=predict(classifier,newdata = testing_set[,-692],
type="class")
#Crear matriz de confusión
cm=table(testing_set[,692],y_pred)
cm
library(randomForest)
classifier=randomForest(x=training_set[,-692],
y=training_set$Liked,
ntree = 5)
#predicción de los resultados con el conjunto de testing
y_pred=predict(classifier,newdata = testing_set[,-692],
type="class")
#Crear matriz de confusión
cm=table(testing_set[,692],y_pred)
cm
classifier=randomForest(x=training_set[,-692],
y=training_set$Liked,
ntree = 12)
#predicción de los resultados con el conjunto de testing
y_pred=predict(classifier,newdata = testing_set[,-692],
type="class")
#Crear matriz de confusión
cm=table(testing_set[,692],y_pred)
cm
classifier=randomForest(x=training_set[,-692],
y=training_set$Liked,
ntree = 11)
#predicción de los resultados con el conjunto de testing
y_pred=predict(classifier,newdata = testing_set[,-692],
type="class")
#Crear matriz de confusión
cm=table(testing_set[,692],y_pred)
cm
